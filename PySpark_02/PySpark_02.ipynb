{"cells":[{"cell_type":"code","source":["Dropping Rows\nVarious Parameter In Dropping functionalities\nFilling Missing Values"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9d3b14fe-dfd3-47f7-8633-e36eeee8ea9d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark=SparkSession.builder.appName('MissingValues').getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"31b5ecdf-16f0-4d09-a72c-c053840ae4af","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_pyspark=spark.read.csv('/FileStore/tables/DataWithNullValues.csv',header=True,inferSchema=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"9a5690fa-2fd2-4cdf-a900-38a71930616f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_pyspark.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c24e86f7-f53b-4dc0-9c97-b5ea646b975b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+----+----------+------+\n|     Name| age|Experience|Salary|\n+---------+----+----------+------+\n|    Krish|  31|        10| 30000|\n|Sudhanshu|  30|         8| 25000|\n|    Sunny|  29|         4| 20000|\n|     Paul|  24|         3| 20000|\n|   Harsha|  21|         1| 15000|\n|  Shubham|  23|         2| 18000|\n|   Mahesh|null|      null| 40000|\n|     null|  34|        10| 38000|\n|     null|  36|      null|  null|\n+---------+----+----------+------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df_pyspark.na.drop().show()  \n# DataFrame.dropna(how='any', thresh=None, subset=None)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e63924eb-03c9-4143-9842-a6bc94936fbd","inputWidgets":{},"title":"Drop Null Rows"}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+---+----------+------+\n|     Name|age|Experience|Salary|\n+---------+---+----------+------+\n|    Krish| 31|        10| 30000|\n|Sudhanshu| 30|         8| 25000|\n|    Sunny| 29|         4| 20000|\n|     Paul| 24|         3| 20000|\n|   Harsha| 21|         1| 15000|\n|  Shubham| 23|         2| 18000|\n+---------+---+----------+------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df_pyspark.na.drop(how=\"any\").show()\n# how = any means delete rows which can have any number of nulls i.e 1 null, 2 null or all values in row are null"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"3a0c1e05-4e00-41f4-8901-6f20f107a3e2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+---+----------+------+\n|     Name|age|Experience|Salary|\n+---------+---+----------+------+\n|    Krish| 31|        10| 30000|\n|Sudhanshu| 30|         8| 25000|\n|    Sunny| 29|         4| 20000|\n|     Paul| 24|         3| 20000|\n|   Harsha| 21|         1| 15000|\n|  Shubham| 23|         2| 18000|\n+---------+---+----------+------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# inserting empty row to dataframe\ncolumns = ['Name', 'age', 'Experience', 'Salary']\nnewRow = spark.createDataFrame([('','','','')], columns )\nappended = df_pyspark.union(newRow)\nappended.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2fb4cebd-ac5e-4ae1-aae3-3cc7d1390c47","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+----+----------+------+\n|     Name| age|Experience|Salary|\n+---------+----+----------+------+\n|    Krish|  31|        10| 30000|\n|Sudhanshu|  30|         8| 25000|\n|    Sunny|  29|         4| 20000|\n|     Paul|  24|         3| 20000|\n|   Harsha|  21|         1| 15000|\n|  Shubham|  23|         2| 18000|\n|   Mahesh|null|      null| 40000|\n|     null|  34|        10| 38000|\n|     null|  36|      null|  null|\n|         |    |          |      |\n+---------+----+----------+------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df_pyspark.na.drop(how=\"all\").show()\n# how = all means delete only those rows which have all values as null"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"be3838c7-9de6-4763-8a53-84eadc972469","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+----+----------+------+\n|     Name| age|Experience|Salary|\n+---------+----+----------+------+\n|    Krish|  31|        10| 30000|\n|Sudhanshu|  30|         8| 25000|\n|    Sunny|  29|         4| 20000|\n|     Paul|  24|         3| 20000|\n|   Harsha|  21|         1| 15000|\n|  Shubham|  23|         2| 18000|\n|   Mahesh|null|      null| 40000|\n|     null|  34|        10| 38000|\n|     null|  36|      null|  null|\n+---------+----+----------+------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#thresh : drop rows that have less than thresh non-null values. This overwrites the how parameter.\ndf_pyspark.na.drop(how=\"any\",thresh=3).show()\n# Drops only those rows which have atleast 3 non-null values"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6e9cfb92-842a-4b25-a6ff-4b2923782ac7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+---+----------+------+\n|     Name|age|Experience|Salary|\n+---------+---+----------+------+\n|    Krish| 31|        10| 30000|\n|Sudhanshu| 30|         8| 25000|\n|    Sunny| 29|         4| 20000|\n|     Paul| 24|         3| 20000|\n|   Harsha| 21|         1| 15000|\n|  Shubham| 23|         2| 18000|\n|     null| 34|        10| 38000|\n+---------+---+----------+------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#  subset : list of column names to consider\ndf_pyspark.na.drop(how=\"any\",subset=['Age']).show()\n# drops null only in age column"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"33dfb858-336f-4b35-9cb3-e1f293e14e3b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+---+----------+------+\n|     Name|age|Experience|Salary|\n+---------+---+----------+------+\n|    Krish| 31|        10| 30000|\n|Sudhanshu| 30|         8| 25000|\n|    Sunny| 29|         4| 20000|\n|     Paul| 24|         3| 20000|\n|   Harsha| 21|         1| 15000|\n|  Shubham| 23|         2| 18000|\n|     null| 34|        10| 38000|\n|     null| 36|      null|  null|\n+---------+---+----------+------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df_pyspark.na.fill('unknown').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2f863943-b30d-445f-abc2-cf6230247422","inputWidgets":{},"title":"Filling Missing Values"}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+----+----------+------+\n|     Name| age|Experience|Salary|\n+---------+----+----------+------+\n|    Krish|  31|        10| 30000|\n|Sudhanshu|  30|         8| 25000|\n|    Sunny|  29|         4| 20000|\n|     Paul|  24|         3| 20000|\n|   Harsha|  21|         1| 15000|\n|  Shubham|  23|         2| 18000|\n|   Mahesh|null|      null| 40000|\n|  unknown|  34|        10| 38000|\n|  unknown|  36|      null|  null|\n+---------+----+----------+------+\n\n"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PySpark_02","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3078958713759781}},"nbformat":4,"nbformat_minor":0}
